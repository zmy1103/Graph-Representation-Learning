## Multi-step Path

[TOC]

### Based on distributed

#### PTransE

**模型介绍：**

​	将知识图谱向量空间模型看成边(关系)的遍历操作, 直接建模路径的中间步, 正则化实体向量的空间分布.组合训练用于不同的表示模型有不同的形式, 例如在TransE中, 组合训练体现为路径上关系向量的加和.模型首先在路径长度为1的数据(三元组)上训练, 然后在所有路径数据上训练, 保证在组合边形成路径前把握基本的边.对于实体间存在多条路径的情况, 上述模型同等地对待这些路径, 没有区分路径的贡献差别, 显然存在实际意义很小的路径.

PTransE： 区别对待实体间的不同路径.PTransE在TransE的基础上多建模了关系路径约束, 通过关系的组合操作建模路径. 依次经过多个关系的路径, 通过关系的组合操作建模, 组合操作可以是路径上关系的加和、连乘等形式, 然后将组合后的路径看成头实体和尾实体之间的转移.对于实体间的多条路径, 可以采用路径约束的资源分配算法权衡关系路径的权重, 用于对路径建模结果进行加权。

**复现：**

https://github.com/mglau/pTransE

https://github.com/Rorschach27/pTransE

#### RPE

**模型介绍：**

​	RPE中, 每个实体通过关系映射矩阵和路径映射矩阵同时映射到对应的关系空间和路径空间, 关系/路径看作映射后的实体之间的转移.路径映射矩阵通过路径上关系对应的映射矩阵加和或连乘得到.由此, 三元组的得分函数包括头尾实体映射到关系空间的转移得分与头尾实体映射到对应的各个路径空间的转移得分之和.类型限制可以从传统的关系指定的类型限制方式扩展到新提出的路径指定的类型限制方式.RPE中, 类型限制用于两个方面:一是训练时负例的选取, 选取和要替换的实体属于同一类型的实体替换, 提高模型的学习能力; 二是测试时, 候选实体从同一类型的实体集选取, 过滤不满足类型限制的实体.目前的知识表示方法大多单独学习每个三元组, PTransE等也仅仅引入了多跳关系信息.

#### GAKE

**模型介绍：**

​	GAKE引入了3类图上下文信息:邻居上下文、路径上下文和边上下文, 从不同角度反映知识属性, 同时设计attention机制, 即实体和关系的权重学习, 学习有代表能力的实体或关系.其中, 邻居上下文反映三元组关系, 实体的邻居上下文为以该实体为头实体的所有三元组中的关系和尾实体对, 关系的邻居上下文为该关系对应的所有三元组中的头实体和尾实体对.路径上下文为多步路径上的实体和关系.实体的边上下文为与该实体相连的所有关系, 关系的边上下文为该关系连接的所有实体.每类上下文的目标函数为给定上下文, 实体/关系的概率函数和.GAKE最大化3类目标函数的加权和.

**复现：**

https://github.com/JuneFeng/GAKE

### Based on neural network

#### (1)神经网络建模多步路径的推理

​	该类方法用神经网络建模路径, 充分学习多步路径的向量表示, 得分函数关联于路径的表示与直接关系表示的相似度, 希望正例对应的相似度大, 即乘积大, 负例小.

​	训练一个单一的高能力RNN, 在路径建模中, 除了建模每步关系, 还建模对应的实体, 共同推理所有的关系、实体和实体类型.其中, 实体向量表示通过实体类型向量表示的简单加和得到, 实体类型向量表示在训练中学习.

#### (2) 神经网络模拟计算机或人脑的推理（不太了解这块）

​	DNC (differentiable neural computer), 包含一个LSTM神经网络控制器和可以读写的外部存储矩阵.训练时, DNC以知识图谱三元组向量作为输入, 通过神经网络进行外部存储矩阵的读写, 模拟人脑利用已有的经验知识学习推理新知识, 并更新已有的知识.测试时, 需要推理预测的三元组对应字段留空(例如预测头实体, 则头实体字段留空), 输入训练好的DNC, 控制器不断与外部存储矩阵交互, 多步推理, 最后输出补全的三元组.

### 参考文献

- Lin X, Liang Y, Guan R. Compositional learning of relation paths embedding for knowledge base completion. arXiv Preprint arXiv: 161107232, 2016.http://cn.arxiv.org/abs/1611.07232
- Feng J, Huang M, Yang Y, Zhu X. GAKE: Graph aware knowledge embedding. In: Proc. of the 26th Int'l Conf. on Computational Linguistics. Stroudsburg: ACL, 2016. 641-651.
-  Das R, Neelakantan A, Belanger D, McCallum A. Chains of reasoning over entities, relations, and text using recurrent neural networks. arXiv Preprint arXiv: 160701426, 2016.http://cn.arxiv.org/abs/1607.01426